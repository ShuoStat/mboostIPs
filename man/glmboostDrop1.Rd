% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glmboostDrop1.R
\name{glmboostDrop1}
\alias{glmboostDrop1}
\title{glmboostDrop1 Function}
\usage{
glmboostDrop1(
  obj,
  nCores = 1,
  fixMstop = NULL,
  aims = c("variableSelection", "prediction"),
  ref = c("mean", "orig."),
  folds = NULL,
  ...
)
}
\arguments{
\item{obj}{An object of class \code{mboost} as returned by the \code{mboost} package
functions. This is the model on which the drop-one analysis will be performed.}

\item{nCores}{Integer specifying the number of cores to use for parallel execution.
If \code{NULL}, the function will use one less than the total number of available cores.}

\item{fixMstop}{Optional; an integer specifying using a fixed mstop
for the gradient boosting algorithm. If \code{NULL}, \code{mstop} is determined automatically.}

\item{aims}{A character vector indicating the aim of the analysis:
"variableSelection" to detect IPs for variable seleciton, "prediction" to
detect IPs for prediction, or both.}

\item{ref}{A character string specifying the reference for comparison in
variable selection and prediction. Can be "mean" for leave-one-out models,
or "orig." for the original model.}

\item{folds}{the same argument in \code{cvrisk()}. a weight matrix with number of
rows equal to the number of observations. The number of columns corresponds
to the number of cross-validation runs. Can be computed using function cv
and defaults to 25 bootstrap samples.}

\item{...}{Additional arguments passed on to cvrisk. see \code{mboost} package.}
}
\value{
A list with three elements:
\itemize{
\item \code{vsScore}: A numeric vector of scores indicating the influence
of each observation on variable selection, if "variableSelection" is
among the aims. \code{NULL} otherwise.
\item \code{PredScores}: A numeric vector of scores indicating the influence of each
observation on prediction, if "prediction" is among the aims.
\code{NULL} otherwise.
\item \code{LooObj}: A list of objects resulting from the LOO analysis, including
details like selected variables, cross-validated risk, and the optimal
stopping iteration for each left-out observation.
}
}
\description{
The \code{glmboostDrop1} function performs a drop-one analysis for models fitted
with gradient boosting, specifically targeting variable selection and
prediction improvements. It can operate in parallel to speed up computations.
}
\details{
The function conducts a leave-one-out (LOO) analysis by re-fitting the model
iteratively with one observation removed, and examining the impact on variable
selection or prediction. In the case of variable selection, the function
calculates the difference in selected variables between the leave-one-out
model and the reference model, which can either be the original model or
the mean of all leave-one-out models. If the goal is prediction, the function
compares the mean of cross-validation error between the leave-one-out model
and a reference model. The function also allows for parallel running by
specifying the number of CPU cores.
}
\examples{

library(mboost)
data(golub99)
X <- golub99$X
X <- scale(X)
y <- golub99$y
set.seed(1) 
foldid <- sample(rep(1:10, length = nrow(X)), nrow(X)) 
cv <- sapply(1:max(foldid), function(x) as.numeric(foldid != x))
obj <- glmboost(X, y,
                family = Binomial(),
                control = boost_control(mstop = 140,
                                        nu = 0.1,
                                        risk = "inbag"), 
                                        center = FALSE)
drop1obj <- glmboostDrop1(obj,
                          nCores = 1,
                          fixMstop = NULL,
                          aims = c("variableSelection", "prediction"),
                          ref = "mean",
                          folds = cv)
plot_Scores(drop1obj)
plot_Path(drop1obj, ref = "mean")

}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glmboostDrop1.R
\name{glmboostDrop1}
\alias{glmboostDrop1}
\title{glmboostDrop1 Function}
\usage{
glmboostDrop1(
  obj,
  nCores = 1,
  fixMstop = NULL,
  aims = c("variableSelection", "prediction"),
  ref = c("mean", "orig."),
  folds = NULL,
  ...
)
}
\arguments{
\item{obj}{An object of class \code{mboost} as returned by the \code{mboost} package
functions. This is the model on which the drop-one analysis will be performed.}

\item{nCores}{Integer specifying the number of cores to use for parallel execution.
If \code{NULL}, the function will use one less than the total number of available cores.}

\item{fixMstop}{Optional; an integer specifying using a fixed mstop
for the gradient boosting algorithm. If \code{NULL}, \code{mstop} is determined automatically.}

\item{aims}{A character vector indicating the aim of the analysis:
"variableSelection" to detect IPs for variable seleciton, "prediction" to
detect IPs for prediction, or both.}

\item{ref}{A character string specifying the reference for comparison in
variable selection and prediction. Can be "mean" for leave-one-out models,
or "orig." for the original model.}

\item{folds}{the same argument in \code{cvrisk()}. a weight matrix with number of
rows equal to the number of observations. The number of columns corresponds
to the number of cross-validation runs. Can be computed using function cv
and defaults to 25 bootstrap samples.}

\item{...}{Additional arguments passed on to cvrisk. see \code{mboost} package.}
}
\value{
A list with three elements:
\itemize{
\item \code{vsScore}: A numeric vector of scores indicating the influence
of each observation on variable selection, if "variableSelection" is
among the aims. \code{NULL} otherwise.
\item \code{PredScores}: A numeric vector of scores indicating the influence of each
observation on prediction, if "prediction" is among the aims.
\code{NULL} otherwise.
\item \code{LooObj}: A list of objects resulting from the LOO analysis, including
details like selected variables, cross-validated risk, and the optimal
stopping iteration for each left-out observation.
}
}
\description{
The \code{glmboostDrop1} function performs a drop-one analysis for models fitted
with gradient boosting, specifically targeting variable selection and
prediction improvements. It can operate in parallel to speed up computations.
}
\details{
The function performs a leave-one-out (LOO) analysis by iteratively re-fitting
the model with one observation left out and evaluating the effect on
variable selection or prediction. For variable selection, it calculates the
difference in selected variables between the leave-one-out model and the
reference. The reference can be the original model or the mean of all
leave-one-out models. If the aim of the selection of

with respect to a reference. This analysis helps in identifying the most
influential observations.
}
\examples{

library(mboost)
data(golub99)
X <- golub99$X
X <- scale(X)
y <- golub99$y
set.seed(1) 
foldid <- sample(rep(1:10, length = nrow(X)), nrow(X)) 
cv <- sapply(1:max(foldid), function(x) as.numeric(foldid != x))
obj <- glmboost(X, y,
                family = Binomial(),
                control = boost_control(mstop = 140,
                                        nu = 0.1,
                                        risk = "inbag"), 
                                        center = FALSE)
drop1obj <- glmboostDrop1(obj,
                          nCores = 1,
                          fixMstop = NULL,
                          aims = c("variableSelection", "prediction"),
                          ref = "mean",
                          folds = cv)
plot_Scores(drop1obj)
plot_Path(drop1obj, ref = "mean")

}
